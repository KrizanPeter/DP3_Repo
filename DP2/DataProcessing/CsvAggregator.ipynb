{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from urllib.request import urlopen\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import copy\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeDataframe():\n",
    "    dff = pd.DataFrame(columns=['date'])\n",
    "    startDate = \"26/03/2019\"\n",
    "    endDate = \"11/10/2019\"\n",
    "    startDate = datetime.datetime.strptime(startDate, \"%d/%m/%Y\")\n",
    "    endDate = datetime.datetime.strptime(endDate, \"%d/%m/%Y\")\n",
    "    insertedDay = startDate\n",
    "    dates = []\n",
    "    while insertedDay < endDate:\n",
    "        dates.append(insertedDay)\n",
    "        insertedDay = insertedDay + datetime.timedelta(days=1)\n",
    "    dff.date = dates\n",
    "    dff = dff.set_index('date')\n",
    "    return dff\n",
    "\n",
    "def EncodeDayOfWeek(dff):\n",
    "    dff['dayOfWeek_sin'] = 0.0\n",
    "    dff['dayOfWeek_cos'] = 0.0\n",
    "    dff['is_Weekend'] = 0\n",
    "    for index, row in dff.iterrows():\n",
    "        dayOfWeek = index.weekday()\n",
    "        dff.at[index,'dayOfWeek_sin'] = math.sin((2*math.pi)/7*dayOfWeek)\n",
    "        dff.at[index,'dayOfWeek_cos'] = math.cos((2*math.pi)/7*dayOfWeek)\n",
    "        if dayOfWeek == 6 or dayOfWeek == 5:\n",
    "            dff.at[index,'is_Weekend'] = 1\n",
    "        else:\n",
    "            dff.at[index,'is_Weekend'] = 0\n",
    "    return dff\n",
    "\n",
    "def CutPdDate(df):\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'date'] = df.at[index, 'date'][:-5]\n",
    "    return df\n",
    "\n",
    "def AddDataFromCsv(dff, path, name, cutTime = True):\n",
    "    transpd = pd.read_csv(path, delimiter=';', names=['date', 'value'])\n",
    "    transpd.drop(transpd.head(1).index, inplace=True)\n",
    "    if cutTime == True:\n",
    "        transpd = CutPdDate(transpd)\n",
    "    dff[name] = 0\n",
    "    \n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in transpd.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name] = float(row2['value'])\n",
    "    diff = np.diff(dff[name])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+name] = diff\n",
    "    return dff\n",
    "\n",
    "def AddOilDataFromCsv(dff, path, name, cutTime = True):\n",
    "    transpd = pd.read_csv(path, delimiter=';', names=['date', 'value'])\n",
    "    transpd.drop(transpd.head(1).index, inplace=True)\n",
    "    if cutTime == True:\n",
    "        transpd = CutPdDate(transpd)\n",
    "    dff[name] = 0.0\n",
    "    \n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in transpd.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name] = float(row2['value'])\n",
    "    \n",
    "    lastPrice = 0;\n",
    "    for index2, row2 in dff.iterrows():\n",
    "        if row2[name] == 0.0:\n",
    "            dff.at[index2, name] = lastPrice\n",
    "        lastPrice = dff.at[index2, name]       \n",
    "                \n",
    "    diff = np.diff(dff[name])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+name] = diff\n",
    "    return dff\n",
    "\n",
    "def AddCurrency(dff, path, name):\n",
    "    dff[name+'_open_price'] = 0.0\n",
    "    dff[name+'_close_price'] = 0.0\n",
    "    dff[name+'_volume'] = 0.0\n",
    "    dff[name+'_market_cap'] = 0.0\n",
    "    dff['d_'+name+'_open_price'] = 0.0\n",
    "    dff['d_'+name+'_close_price'] = 0.0\n",
    "    dff['d_'+name+'_volume'] = 0.0\n",
    "    dff['d_'+name+'_market_cap'] = 0.0\n",
    "     \n",
    "    transpd = pd.read_csv(path, delimiter=';')\n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in transpd.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name+'_open_price'] = float(row2['open_price_'+name])\n",
    "                dff.at[index1, name+'_close_price'] = float(row2['close_price_'+name])\n",
    "                dff.at[index1, name+'_volume'] = float(row2['volume_'+name])\n",
    "                dff.at[index1, name+'_market_cap'] = float(row2['market_cap_'+name])\n",
    "                continue\n",
    "                \n",
    "    dff['d_'+name+'_open_price'] = np.insert(np.diff(dff[name+'_open_price']), 0, 0)\n",
    "    dff['d_'+name+'_close_price'] = np.insert(np.diff(dff[name+'_close_price']), 0, 0)\n",
    "    dff['d_'+name+'_volume'] = np.insert(np.diff(dff[name+'_volume']), 0, 0)\n",
    "    dff['d_'+name+'_market_cap'] = np.insert(np.diff(dff[name+'_market_cap']), 0, 0)\n",
    "    return dff\n",
    "                \n",
    "    \n",
    "def AddStockDataFromCsv(dff, path, name, cutTime = True):\n",
    "    oldname = name\n",
    "    name = name+'_price'\n",
    "    transpd = pd.read_csv(path, delimiter=';')\n",
    "    if cutTime == True:\n",
    "        transpd = CutPdDate(transpd)\n",
    "    dff[name] = 0.0\n",
    "    dff[oldname+'_volume'] = 0.0\n",
    "    \n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in transpd.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name] = float(row2['close'])\n",
    "                dff.at[index1, oldname+'_volume'] = float(row2['volume'])             \n",
    "\n",
    "    lastPrice = 0;\n",
    "    for index2, row2 in dff.iterrows():\n",
    "        if row2[name] == 0.0:\n",
    "            dff.at[index2, name] = lastPrice\n",
    "        lastPrice = dff.at[index2, name]       \n",
    "                \n",
    "    diff = np.diff(dff[name])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+name] = diff\n",
    "    \n",
    "    diff = np.diff(dff[oldname+'_volume'])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+oldname+'_volume'] = diff\n",
    "    return dff\n",
    "\n",
    "def AddMarketPrices(dff):\n",
    "    marketdf = pd.read_csv(\"market_data/bitcoin_market_price.csv\", delimiter=';')\n",
    "    dff['open_price'] = 0.0\n",
    "    dff['close_price'] = 0.0\n",
    "    dff['market_volume'] = 0.0\n",
    "    dff['market_cap'] = 0.0\n",
    "    for indexf, rowf in dff.iterrows():\n",
    "        print(str(indexf) +' is actually processing!', end='\\r')\n",
    "        for index, row in marketdf.iterrows():\n",
    "            date_m = datetime.datetime.strptime(row['Date'], \"%d.%m.%Y\")\n",
    "            if(indexf == date_m):\n",
    "                dff.at[indexf,'open_price'] = row['Open'].replace(',','')\n",
    "                dff.at[indexf,'close_price'] = row['Close'].replace(',','')\n",
    "                dff.at[indexf,'market_volume'] = row['Volume'].replace(',','')\n",
    "                dff.at[indexf,'market_cap'] = row['Market Cap'].replace(',','')\n",
    "                continue\n",
    "    #dff['target_open_price'] = np.append(np.diff(dff['open_price']), [0])\n",
    "    #dff['target_close_price'] = np.append(np.diff(dff['close_price']), [0])\n",
    "    #dff['target_rise_fall'] = (dff.target_close_price>0.0)\n",
    "    \n",
    "    \n",
    "    #dff['d_open_price'] = np.insert(np.diff(dff['open_price']),0, [0])\n",
    "    #dff['d_close_price'] = np.insert(np.diff(dff['close_price']),0, [0])\n",
    "    #dff['d_market_volume'] = np.insert(np.diff(dff['market_volume']),0, [0])\n",
    "    #dff['d_market_cap'] = np.insert(np.diff(dff['market_cap']),0, [0])\n",
    "    return dff\n",
    "\n",
    "def AddTwitterSentimentData(dff):\n",
    "    dff['tweet_volume'] = 0\n",
    "    \n",
    "    dff['nonzero_neutral_tweet']  = 0\n",
    "    dff['nonzero_positive_tweet'] = 0\n",
    "    dff['nonzero_negative_tweet'] = 0\n",
    "    dff['nonzero_compound_tweet'] = 0\n",
    "    \n",
    "    dff['sum_positive_mul_follow'] = 0.0\n",
    "    dff['sum_neutral_mul_follow']  = 0.0\n",
    "    dff['sum_negative_mul_follow'] = 0.0\n",
    "    dff['sum_compound_mul_follow'] = 0.0\n",
    "    \n",
    "    dff['sum_positive'] = 0.0\n",
    "    dff['sum_neutral']  = 0.0\n",
    "    dff['sum_negative'] = 0.0\n",
    "    dff['sum_compound'] = 0.0\n",
    "    \n",
    "    dff['avg_sum_positive'] = 0.0\n",
    "    dff['avg_sum_neutral']  = 0.0\n",
    "    dff['avg_sum_negative'] = 0.0\n",
    "    dff['avg_sum_compound'] = 0.0\n",
    "    \n",
    "    dff['avg_sum_nonzero_positive'] = 0.0\n",
    "    dff['avg_sum_nonzero_neutral']  = 0.0\n",
    "    dff['avg_sum_nonzero_negative'] = 0.0\n",
    "    dff['avg_sum_nonzero_compound'] = 0.0\n",
    "    \n",
    "    dff['avg_sum_positive_mul_follow'] = 0.0\n",
    "    dff['avg_sum_neutral_mul_follow']  = 0.0\n",
    "    dff['avg_sum_negative_mul_follow'] = 0.0\n",
    "    dff['avg_sum_compound_mul_follow'] = 0.0\n",
    "    \n",
    "    dff['avg_sum_nonzero_positive_mul_follow'] = 0.0\n",
    "    dff['avg_sum_nonzero_neutral_mul_follow']  = 0.0\n",
    "    dff['avg_sum_nonzero_negative_mul_follow'] = 0.0\n",
    "    dff['avg_sum_nonzero_compound_mul_follow'] = 0.0\n",
    "        \n",
    "    for index, row in dff.iterrows():\n",
    "        print(str(index) +' is actually processing!', end='\\r')\n",
    "        \n",
    "        filedate = 'data_done/'+str(index).split(' ')[0]+'.csv'\n",
    "        tdff = pd.read_csv(filedate, encoding=\"utf-16\", engine='python')\n",
    "        \n",
    "        tdff['positive_mult_follow'] = tdff.positive * tdff.user_follower\n",
    "        tdff['neutral_mult_follow']  = tdff.neutral * tdff.user_follower\n",
    "        tdff['negative_mult_follow'] = tdff.negative * tdff.user_follower\n",
    "        tdff['compound_mult_follow'] = tdff['compound'] * tdff.user_follower\n",
    "        \n",
    "        volume = len(tdff.index)\n",
    "\n",
    "        nonZero_neut = (tdff.neutral>0.0).sum()\n",
    "        nonZero_pos  = (tdff.positive>0.0).sum()\n",
    "        nonZero_neg  = (tdff.negative>0.0).sum()\n",
    "        nonZero_comp = (tdff['compound']>0.0).sum()\n",
    "        \n",
    "        sum_neut = tdff.neutral.sum()\n",
    "        sum_pos  = tdff.positive.sum()\n",
    "        sum_neg  = tdff.negative.sum()\n",
    "        sum_comp = tdff['compound'].sum()\n",
    "        \n",
    "        sum_positive_mul_follow = tdff['positive_mult_follow'].sum()\n",
    "        sum_neutral_mul_follow  = tdff['neutral_mult_follow'].sum()\n",
    "        sum_negative_mul_follow = tdff['negative_mult_follow'].sum()\n",
    "        sum_compound_mul_follow = tdff['compound_mult_follow'].sum()\n",
    "        \n",
    "        #fill dataframe\n",
    "        dff.at[index,'tweet_volume'] = volume\n",
    "        \n",
    "        dff.at[index,'nonzero_neutral_tweet']  = nonZero_neut\n",
    "        dff.at[index,'nonzero_positive_tweet'] = nonZero_pos\n",
    "        dff.at[index,'nonzero_negative_tweet'] = nonZero_neg\n",
    "        dff.at[index,'nonzero_compound_tweet'] = nonZero_comp\n",
    "                \n",
    "        dff.at[index,'sum_positive_mul_follow'] = sum_positive_mul_follow\n",
    "        dff.at[index,'sum_neutral_mul_follow']  = sum_neutral_mul_follow\n",
    "        dff.at[index,'sum_negative_mul_follow'] = sum_negative_mul_follow\n",
    "        dff.at[index,'sum_compound_mul_follow'] = sum_compound_mul_follow\n",
    "    \n",
    "        dff.at[index,'sum_positive'] = sum_pos\n",
    "        dff.at[index,'sum_neutral']  = sum_neut\n",
    "        dff.at[index,'sum_negative'] = sum_neg\n",
    "        dff.at[index,'sum_compound'] = sum_comp\n",
    "               \n",
    "        dff.at[index,'avg_sum_positive'] = sum_pos  / volume\n",
    "        dff.at[index,'avg_sum_neutral']  = sum_neut / volume\n",
    "        dff.at[index,'avg_sum_negative'] = sum_neg  / volume\n",
    "        dff.at[index,'avg_sum_compound'] = sum_comp / volume\n",
    "        \n",
    "        dff.at[index,'avg_sum_nonzero_positive'] = sum_pos  / nonZero_pos\n",
    "        dff.at[index,'avg_sum_nonzero_neutral']  = sum_neut / nonZero_neut\n",
    "        dff.at[index,'avg_sum_nonzero_negative'] = sum_neg  / nonZero_neg\n",
    "        dff.at[index,'avg_sum_nonzero_compound'] = sum_comp / nonZero_comp\n",
    "        \n",
    "        dff.at[index,'avg_sum_positive_mul_follow'] = sum_positive_mul_follow / volume\n",
    "        dff.at[index,'avg_sum_neutral_mul_follow']  = sum_neutral_mul_follow  / volume\n",
    "        dff.at[index,'avg_sum_negative_mul_follow'] = sum_negative_mul_follow / volume\n",
    "        dff.at[index,'avg_sum_compound_mul_follow'] = sum_compound_mul_follow / volume\n",
    "        \n",
    "        dff.at[index, 'avg_sum_nonzero_positive_mul_follow'] = sum_positive_mul_follow / nonZero_pos\n",
    "        dff.at[index, 'avg_sum_nonzero_neutral_mul_follow']  = sum_neutral_mul_follow  / nonZero_neut\n",
    "        dff.at[index, 'avg_sum_nonzero_negative_mul_follow'] = sum_negative_mul_follow / nonZero_neg\n",
    "        dff.at[index, 'avg_sum_nonzero_compound_mul_follow'] = sum_compound_mul_follow / nonZero_comp\n",
    "    \n",
    "    #dff['d_tweet_volume'] = np.insert(np.diff(dff['tweet_volume']),0, [0])\n",
    "    return dff\n",
    "\n",
    "def AddCobaltPrice(dff):\n",
    "    dff['cobalt_price'] = 0.0\n",
    "    cdf = pd.read_csv(\"_stockdata/cobalt_data.csv\", delimiter=';')\n",
    "    name = 'cobalt_price'\n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in cdf.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['Date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name] = float(row2['Price'])\n",
    "    \n",
    "    #ensure empty dates - fill last known price\n",
    "    lastPrice = 0;\n",
    "    for index2, row2 in dff.iterrows():\n",
    "        if row2['cobalt_price'] == 0.0:\n",
    "            dff.at[index2, name] = lastPrice\n",
    "        lastPrice = dff.at[index2, name]\n",
    "                \n",
    "    diff = np.diff(dff[name])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+name] = diff\n",
    "        \n",
    "    return dff\n",
    "\n",
    "def AddNewsAggregatedData(dff):\n",
    "    ndf = pd.read_csv(\"twitter_data/news_with_sentiment.csv\")\n",
    "    \n",
    "    for index1, row1 in dff.iterrows():\n",
    "        print(str(index1) +' is actually processing!', end='\\r')\n",
    "\n",
    "        numberOfDailyNews = 0\n",
    "        tags = ''\n",
    "        cleaned_headertext_sent_neg = 0.0\n",
    "        cleaned_headertext_sent_neut = 0.0\n",
    "        cleaned_headertext_sent_pos = 0.0\n",
    "        cleaned_headertext_sent_comp = 0.0\n",
    "        headertext_sent_neg = 0.0\n",
    "        headertext_sent_neut = 0.0\n",
    "        headertext_sent_pos = 0.0\n",
    "        headertext_sent_comp = 0.0\n",
    "        contenttext_sent_neg = 0.0\n",
    "        contenttext_sent_neut = 0.0\n",
    "        contenttext_sent_pos = 0.0\n",
    "        contenttext_sent_comp = 0.0\n",
    "        cleaned_contenttext_sent_neg = 0.0\n",
    "        cleaned_contenttext_sent_neut = 0.0\n",
    "        cleaned_contenttext_sent_pos = 0.0\n",
    "        cleaned_contenttext_sent_comp = 0.0\n",
    "\n",
    "        for index2, row2 in ndf.iterrows():\n",
    "            date = datetime.datetime.strptime(str(row2['date']).split(' ')[0], \"%Y-%m-%d\")\n",
    "            if(index1 == date):\n",
    "                numberOfDailyNews = numberOfDailyNews + 1\n",
    "                tags = tags + row2['tags']\n",
    "                cleaned_headertext_sent_neg += row2['cleaned_headertext_sent_neg']\n",
    "                cleaned_headertext_sent_neut += row2['cleaned_headertext_sent_neut']\n",
    "                cleaned_headertext_sent_pos += row2['cleaned_headertext_sent_pos']\n",
    "                cleaned_headertext_sent_comp += row2['cleaned_headertext_sent_comp']\n",
    "                headertext_sent_neg += row2['headertext_sent_neg']\n",
    "                headertext_sent_neut += row2['headertext_sent_neut']\n",
    "                headertext_sent_pos += row2['headertext_sent_pos']\n",
    "                headertext_sent_comp += row2['headertext_sent_comp']\n",
    "                contenttext_sent_neg += row2['contenttext_sent_neg']\n",
    "                contenttext_sent_neut += row2['contenttext_sent_neut']\n",
    "                contenttext_sent_pos += row2['contenttext_sent_pos']\n",
    "                contenttext_sent_comp += row2['contenttext_sent_comp']\n",
    "                cleaned_contenttext_sent_neg += row2['cleaned_contenttext_sent_neg']\n",
    "                cleaned_contenttext_sent_neut += row2['cleaned_contenttext_sent_neut']\n",
    "                cleaned_contenttext_sent_pos += row2['cleaned_contenttext_sent_pos']\n",
    "                cleaned_contenttext_sent_comp += row2['cleaned_contenttext_sent_comp']\n",
    "\n",
    "        if numberOfDailyNews == 0:\n",
    "            numberOfDailyNews = 1\n",
    "            \n",
    "        dff.at[index1,'sum_clheaders_negative']  = cleaned_headertext_sent_neg\n",
    "        dff.at[index1,'sum_clheaders_positive']  = cleaned_headertext_sent_pos\n",
    "        dff.at[index1,'sum_clheaders_neutral']  = cleaned_headertext_sent_neut\n",
    "        dff.at[index1,'sum_clheaders_compound']  = cleaned_headertext_sent_comp\n",
    "\n",
    "        dff.at[index1,'avg_clheaders_negative']  = cleaned_headertext_sent_neg  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clheaders_positive']  = cleaned_headertext_sent_pos  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clheaders_neutral']  = cleaned_headertext_sent_neut  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clheaders_compound']  = cleaned_headertext_sent_comp / numberOfDailyNews\n",
    "\n",
    "        dff.at[index1,'sum_headers_negative']  = headertext_sent_neg\n",
    "        dff.at[index1,'sum_headers_positive']  = headertext_sent_pos\n",
    "        dff.at[index1,'sum_headers_neutral']  = headertext_sent_neut\n",
    "        dff.at[index1,'sum_headers_compound']  = headertext_sent_comp\n",
    "\n",
    "        dff.at[index1,'avg_headers_negative']  = headertext_sent_neg  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_headers_positive']  = headertext_sent_pos  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_headers_neutral']  = headertext_sent_neut  / numberOfDailyNews\n",
    "        dff.at[index1,'avg_headers_compound']  = headertext_sent_comp / numberOfDailyNews\n",
    "\n",
    "        dff.at[index1,'sum_clcontents_negative']  = cleaned_contenttext_sent_neg\n",
    "        dff.at[index1,'sum_clcontents_positive']  = cleaned_contenttext_sent_pos\n",
    "        dff.at[index1,'sum_clcontents_neutral']  = cleaned_contenttext_sent_neut\n",
    "        dff.at[index1,'sum_clcontents_compound']  = cleaned_contenttext_sent_comp\n",
    "\n",
    "        dff.at[index1,'avg_clcontents_negative']  = cleaned_contenttext_sent_neg / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clcontents_positive']  = cleaned_contenttext_sent_pos / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clcontents_neutral']  = cleaned_contenttext_sent_neut / numberOfDailyNews\n",
    "        dff.at[index1,'avg_clcontents_compound']  = cleaned_contenttext_sent_comp / numberOfDailyNews\n",
    "\n",
    "        dff.at[index1,'sum_contents_negative']  = contenttext_sent_neg\n",
    "        dff.at[index1,'sum_contents_positive']  = contenttext_sent_pos\n",
    "        dff.at[index1,'sum_contents_neutral']  = contenttext_sent_neut\n",
    "        dff.at[index1,'sum_contents_compound']  = contenttext_sent_comp\n",
    "\n",
    "        dff.at[index1,'avg_contents_negative']  = contenttext_sent_neg / numberOfDailyNews\n",
    "        dff.at[index1,'avg_contents_positive']  = contenttext_sent_pos / numberOfDailyNews\n",
    "        dff.at[index1,'avg_contents_neutral']  = contenttext_sent_neut / numberOfDailyNews\n",
    "        dff.at[index1,'avg_contents_compound']  = contenttext_sent_comp / numberOfDailyNews\n",
    "        \n",
    "    return dff\n",
    "\n",
    "def AddFearIndex(dff):\n",
    "    \n",
    "    cdf = pd.read_csv(\"_fearfactorindex/fear_factor.csv\", delimiter=';')\n",
    "    name = 'fear_factor'\n",
    "    for index1, row1 in dff.iterrows():\n",
    "        for index2, row2 in cdf.iterrows():\n",
    "            date = datetime.datetime.strptime(row2['date'], \"%d.%m.%Y\")\n",
    "            if(index1 == date):\n",
    "                dff.at[index1, name+'_index'] = float(row2['fear_index'])\n",
    "                dff.at[index1, name+'_class'] = row2['clasification']\n",
    "               \n",
    "    diff = np.diff(dff[name+'_index'])        \n",
    "    diff = np.insert(diff, 0, [0])\n",
    "    dff['d_'+name] = diff\n",
    "        \n",
    "    return dff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = InitializeDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-10 00:00:00 is actually processing!\r"
     ]
    }
   ],
   "source": [
    "dff = AddMarketPrices(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = EncodeDayOfWeek(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'bitcoin_blockchain_data/confirmed_transactions.csv', 'num_of_transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'bitcoin_blockchain_data/miners_revenue.csv', 'miners_revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'bitcoin_blockchain_data/output_volume.csv', 'output_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'bitcoin_blockchain_data/total_transactions_fees.csv', 'total_trans_fees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'google_trends/bitcoin_trends.csv', 'bitcoin_trends', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddDataFromCsv(dff, 'google_trends/cryptocurrency_trends.csv', 'crypto_trends', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-10 00:00:00 is actually processing!\r"
     ]
    }
   ],
   "source": [
    "dff = AddTwitterSentimentData(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCobaltPrice(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddOilDataFromCsv(dff, '_stockdata/oil_prices.csv', 'oil_price', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddStockDataFromCsv(dff, '_stockdata/amd_prices.csv', 'amd', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddStockDataFromCsv(dff, '_stockdata/intel_prices.csv', 'intel', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddStockDataFromCsv(dff, '_stockdata/nvidia_prices.csv', 'nvidia', cutTime = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-10 00:00:00 is actually processing!\r"
     ]
    }
   ],
   "source": [
    "dff = AddNewsAggregatedData(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddFearIndex(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/btccash_data.csv', 'btccash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/ethereum_data.csv', 'ethereum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/litecoin_data.csv', 'litecoin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/maker_data.csv', 'maker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/monero_data.csv', 'monero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = AddCurrency(dff, 'currency_data/xrp_data.csv', 'xrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(\"_finalDataset/data_f.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
